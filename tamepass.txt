
# project_structure = '''
# # FRA Synthetic Data Generation Project Structure

# fra_synthetic_data_generator/
# │
# ├── README.md                          # Project documentation
# ├── requirements.txt                   # Python dependencies
# ├── setup.py                          # Package installation script
# │
# ├── src/                              # Source code directory
# │   ├── __init__.py
# │   ├── transformer_circuit_model.py  # Physics-based circuit modeling
# │   ├── fault_simulation.py          # Fault injection and simulation
# │   ├── synthetic_data_generator.py   # Main data generation class
# │   ├── physics_validation.py        # Physics constraint validation
# │   ├── data_export_utils.py         # Multi-format data export utilities
# │   └── main_pipeline.py             # Complete pipeline execution
# │
# ├── config/                           # Configuration files
# │   ├── default_config.yaml          # Default pipeline configuration
# │   ├── transformer_specs.json       # Transformer specification templates
# │   └── fault_parameters.json        # Fault simulation parameters
# │
# ├── data/                            # Generated data storage
# │   ├── raw/                         # Raw generated datasets
# │   ├── processed/                   # Processed/validated datasets
# │   ├── exports/                     # Vendor format exports
# │   └── samples/                     # Sample data for visualization
# │
# ├── tests/                           # Unit tests
# │   ├── __init__.py
# │   ├── test_circuit_model.py
# │   ├── test_fault_simulation.py
# │   ├── test_data_generation.py
# │   ├── test_physics_validation.py
# │   └── test_export_utils.py
# │
# ├── notebooks/                       # Jupyter notebooks for analysis
# │   ├── 01_circuit_model_exploration.ipynb
# │   ├── 02_fault_simulation_analysis.ipynb
# │   ├── 03_data_generation_demo.ipynb
# │   ├── 04_physics_validation_study.ipynb
# │   └── 05_dataset_analysis.ipynb
# │
# ├── scripts/                         # Utility scripts
# │   ├── generate_dataset.py          # Simple dataset generation script
# │   ├── validate_data.py            # Standalone validation script
# │   ├── export_vendor_formats.py    # Vendor format export script
# │   └── visualize_samples.py        # Data visualization script
# │
# ├── docs/                            # Documentation
# │   ├── user_guide.md               # User guide and tutorials
# │   ├── api_reference.md            # API documentation
# │   ├── physics_background.md       # Physics theory background
# │   └── examples/                    # Usage examples
# │       ├── basic_usage.py
# │       ├── custom_configuration.py
# │       └── ml_integration.py
# │
# └── outputs/                         # Default output directory
#     ├── datasets/                    # Generated datasets
#     ├── reports/                     # Validation reports
#     ├── plots/                       # Generated plots
#     └── logs/                        # Pipeline logs
# '''

# usage_examples = '''
# # Usage Examples for FRA Synthetic Data Generator

# ## 1. Basic Usage
# ```python
# from src.main_pipeline import FRAPipeline

# # Create pipeline with default configuration
# pipeline = FRAPipeline()

# # Generate dataset
# results = pipeline.run_complete_pipeline()

# print(f"Generated {results['report']['dataset_statistics']['total_samples']} samples")
# ```

# ## 2. Custom Configuration
# ```python
# config = {
#     'n_samples': 50000,
#     'validation_split': 0.2,
#     'test_split': 0.1,
#     'output_dir': './my_fra_data',
#     'export_formats': ['hdf5', 'tensorflow', 'pytorch'],
#     'vendor_formats': ['omicron', 'megger', 'doble'],
#     'quality_threshold': 0.9
# }

# pipeline = FRAPipeline(config)
# results = pipeline.run_complete_pipeline()
# ```

# ## 3. Individual Component Usage
# ```python
# from src.transformer_circuit_model import TransformerCircuitModel
# from src.fault_simulation import FaultSimulator, FaultType

# # Create transformer model
# transformer = TransformerCircuitModel(
#     n_sections=15, 
#     voltage_level=132.0, 
#     power_rating=50.0
# )

# # Create fault simulator
# fault_sim = FaultSimulator()

# # Generate healthy response
# freq, mag, phase = transformer.calculate_frequency_response()

# # Apply fault
# faulty_params = fault_sim.apply_fault(
#     transformer.baseline_params, 
#     FaultType.AXIAL_DISPLACEMENT, 
#     severity=35.0
# )

# # Calculate faulty response
# freq_f, mag_f, phase_f = transformer.calculate_frequency_response(faulty_params)
# ```

# ## 4. Machine Learning Integration
# ```python
# import numpy as np
# from sklearn.ensemble import RandomForestClassifier
# import h5py

# # Load dataset
# with h5py.File('synthetic_fra_dataset.h5', 'r') as f:
#     X_train = f['train/magnitudes'][:]
#     y_train = f['train/fault_types'][:]
#     X_test = f['test/magnitudes'][:]
#     y_test = f['test/fault_types'][:]

# # Train classifier
# clf = RandomForestClassifier(n_estimators=100)
# clf.fit(X_train, y_train)

# # Evaluate
# accuracy = clf.score(X_test, y_test)
# print(f"Fault detection accuracy: {accuracy:.3f}")
# ```

# ## 5. Command Line Usage
# ```bash
# # Basic generation
# python src/main_pipeline.py --samples 10000

# # Advanced options
# python src/main_pipeline.py \
#     --samples 50000 \
#     --output-dir ./large_dataset \
#     --formats hdf5 numpy tensorflow \
#     --seed 123

# # Skip validation for faster generation
# python src/main_pipeline.py --samples 100000 --no-validation
# ```
# '''

# print("Created requirements.txt")
# print("Created project structure documentation") 
# print("Created usage examples")

# # Save files
# with open("requirements.txt", "w") as f:
#     f.write(requirements_txt)

# with open("project_structure.md", "w") as f:
#     f.write(project_structure)

# with open("usage_examples.md", "w") as f:
#     f.write(usage_examples)

