"""
fra_model_fixed.py

Enhanced FRA Multi-Task Model for Physics-Informed Synthetic Data

Trains on frequency-banded features and metadata to predict:
 - Anomaly detection (binary classification)
 - Fault type classification (multi-class)
 - Severity estimation (regression)
 - Criticality scoring (regression)

Uses “fra_features_summary.csv” generated by the enhanced FRA synthetic data pipeline.
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import RobustScaler, LabelEncoder
from sklearn.model_selection import StratifiedShuffleSplit
from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')


def load_and_preprocess_data(csv_path="fra_features_summary.csv"):
    """Load and preprocess the enhanced FRA synthetic dataset."""
    
    df = pd.read_csv(csv_path)
    print(f"Loaded dataset with {len(df)} samples and {len(df.columns)} columns")
    
    # Define expected features
    band_names = ["VLF", "LF", "MF", "HF"]
    band_features = [
        f"{stat}_{band}"
        for band in band_names
        for stat in ["mag_mean", "mag_std", "mag_min", "mag_max",
                     "ph_mean", "ph_std", "ph_min", "ph_max"]
    ]
    basic_features = ['mag_first', 'mag_peak', 'ph_first']
    metadata_features = ['voltage_kv', 'power_mva', 'age_years']
    
    features = [f for f in band_features + basic_features + metadata_features if f in df.columns]
    print(f"Using {len(features)} input features")
    
    # One-hot encode operational environment if present
    if 'operational_env' in df.columns:
        df = pd.get_dummies(df, columns=['operational_env'], prefix='env')
        env_feats = [c for c in df.columns if c.startswith('env_')]
        features += env_feats
        print(f"Added {len(env_feats)} environment features")
    
    # Extract feature matrix
    X = df[features].fillna(0.0).values
    scaler = RobustScaler().fit(X)
    X_scaled = scaler.transform(X)
    
    # Encode targets
    y_anomaly = df['anomaly'].astype(np.float32).values
    le = LabelEncoder().fit(df['fault_type'])
    y_fault = le.transform(df['fault_type'])
    y_fault_onehot = tf.keras.utils.to_categorical(y_fault)
    
    y_severity = df['severity'].astype(np.float32).values
    y_criticality = df['criticality'].astype(np.float32).values
    
    print(f"Detected {len(le.classes_)} fault classes: {list(le.classes_)}")
    return X_scaled, y_anomaly, y_fault_onehot, y_severity, y_criticality, scaler, le, features


def create_model(input_dim, num_fault_classes):
    """Builds the multi-task model with enhanced architecture."""
    
    inputs = tf.keras.Input(shape=(input_dim,), name="features")
    
    # Shared trunk
    x = tf.keras.layers.Dense(256, activation="relu")(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Dropout(0.3)(x)
    
    x = tf.keras.layers.Dense(128, activation="relu")(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Dropout(0.3)(x)
    
    # Residual branch
    res = tf.keras.layers.Dense(128, activation="relu")(inputs)
    x = tf.keras.layers.Add()([x, res])
    
    x = tf.keras.layers.Dense(64, activation="relu")(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Dropout(0.2)(x)
    
    # Anomaly head
    a = tf.keras.layers.Dense(32, activation="relu")(x)
    a = tf.keras.layers.Dropout(0.2)(a)
    anomaly_output = tf.keras.layers.Dense(1, activation="sigmoid", name="anomaly")(a)
    
    # Fault type head
    f = tf.keras.layers.Dense(64, activation="relu")(x)
    f = tf.keras.layers.Dropout(0.2)(f)
    fault_output = tf.keras.layers.Dense(num_fault_classes, activation="softmax", name="fault_type")(f)
    
    # Severity head
    s = tf.keras.layers.Dense(32, activation="relu")(x)
    s = tf.keras.layers.Dropout(0.1)(s)
    severity_output = tf.keras.layers.Dense(1, activation="sigmoid", name="severity")(s)
    
    # Criticality head
    c = tf.keras.layers.Dense(32, activation="relu")(x)
    c = tf.keras.layers.Dropout(0.1)(c)
    critical_output = tf.keras.layers.Dense(1, activation="sigmoid", name="criticality")(c)
    
    model = tf.keras.Model(
        inputs=inputs,
        outputs=[anomaly_output, fault_output, severity_output, critical_output],
        name="fra_multi_task_fixed"
    )
    return model


def train_model():
    """Loads data, trains the multi-task model, and evaluates performance."""
    
    # Load data
    X, ya, yf, ys, yc, scaler, le, feature_names = load_and_preprocess_data()
    num_classes = yf.shape[1]
    
    # Stratified split on anomaly label
    sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
    train_idx, test_idx = next(sss.split(X, ya))
    
    X_train, X_test = X[train_idx], X[test_idx]
    ya_train, ya_test = ya[train_idx], ya[test_idx]
    yf_train, yf_test = yf[train_idx], yf[test_idx]
    ys_train, ys_test = ys[train_idx], ys[test_idx]
    yc_train, yc_test = yc[train_idx], yc[test_idx]
    
    print(f"Training samples: {len(X_train)}, Test samples: {len(X_test)}")
    
    # Build and compile model
    model = create_model(X_train.shape[1], num_classes)
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3, clipnorm=1.0),
        loss={
            "anomaly": "binary_crossentropy",
            "fault_type": "categorical_crossentropy",
            "severity": "huber",
            "criticality": "huber"
        },
        loss_weights={
            "anomaly": 1.2,
            "fault_type": 1.0,
            "severity": 0.8,
            "criticality": 0.6
        },
        metrics={
            "anomaly": ["accuracy", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()],
            "fault_type": ["accuracy", tf.keras.metrics.TopKCategoricalAccuracy(k=2)],
            "severity": ["mae", tf.keras.metrics.RootMeanSquaredError()],
            "criticality": ["mae", tf.keras.metrics.RootMeanSquaredError()]
        }
    )
    
    callbacks = [
        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=7, factor=0.5, min_lr=1e-6, verbose=1),
        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),
        tf.keras.callbacks.ModelCheckpoint('best_fra_model.h5', save_best_only=True, monitor='val_loss', verbose=1)
    ]
    
    # Train (no class_weight, single multi-output model)
    history = model.fit(
        X_train,
        {"anomaly": ya_train, "fault_type": yf_train, "severity": ys_train, "criticality": yc_train},
        validation_data=(X_test, {"anomaly": ya_test, "fault_type": yf_test, "severity": ys_test, "criticality": yc_test}),
        epochs=100,
        batch_size=64,
        callbacks=callbacks,
        verbose=1
    )
    
    # Evaluate
    print("\n=== Model Evaluation ===")
    results = model.evaluate(
        X_test,
        {"anomaly": ya_test, "fault_type": yf_test, "severity": ys_test, "criticality": yc_test},
        return_dict=True,
        verbose=0
    )
    print(f"Total Loss: {results['loss']:.4f}")
    print(f"Anomaly - Loss: {results['anomaly_loss']:.4f}, Acc: {results['anomaly_accuracy']:.4f}, Prec: {results['anomaly_precision']:.4f}, Rec: {results['anomaly_recall']:.4f}")
    print(f"Fault Type - Loss: {results['fault_type_loss']:.4f}, Acc: {results['fault_type_accuracy']:.4f}, Top-2 Acc: {results['fault_type_top_k_categorical_accuracy']:.4f}")
    print(f"Severity - Loss: {results['severity_loss']:.6f}, MAE: {results['severity_mae']:.4f}")
    print(f"Criticality - Loss: {results['criticality_loss']:.6f}, MAE: {results['criticality_mae']:.4f}")
    
    # Detailed reports
    ya_pred, yf_pred, ys_pred, yc_pred = model.predict(X_test, verbose=0)
    print("\nAnomaly Classification Report:")
    print(classification_report(ya_test, (ya_pred>0.5).astype(int), target_names=['Healthy','Anomaly'], digits=4))
    
    print("\nFault Type Classification Report:")
    print(classification_report(np.argmax(yf_test, axis=1), np.argmax(yf_pred, axis=1), target_names=le.classes_, digits=4))
    
    print("\nSeverity Regression Metrics:")
    print(f"MSE: {mean_squared_error(ys_test, ys_pred):.6f}, MAE: {mean_absolute_error(ys_test, ys_pred):.6f}, R2: {r2_score(ys_test, ys_pred):.4f}")
    
    print("\nCriticality Regression Metrics:")
    print(f"MSE: {mean_squared_error(yc_test, yc_pred):.6f}, MAE: {mean_absolute_error(yc_test, yc_pred):.6f}, R2: {r2_score(yc_test, yc_pred):.4f}")
    
    return model, history, scaler, le


if __name__ == "__main__":
    model, history, scaler, le = train_model()
    print("\nTraining complete. Best model saved to 'best_fra_model.h5'.")
